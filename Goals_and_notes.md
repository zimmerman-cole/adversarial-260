# Goals

Examine effects of adversarial training on:
* Accuracy (is there a tradeoff?)
* Generalization (does it increase it? decrease it? not affect it?)

* How does adversarial training on examples from white-box attack method A make the network more robust to examples generated by black-box attack method B?

# Tasks

* Create target MNIST network
* Implement attack method A - PGD/multi-step FGSM
* Implement attack method B - some black-box attack method

# Notes
